# 5.2: Enriching Data

In this lesson, you’ll learn about different use cases for enriching data. One particular use case is how to denormalize data into a single index in order to improve the response time of a query. In this lesson, you will also learn how to denormalize data using the enrich processor in an ingest node pipeline.


In this lab, you will learn how to enrich an index by performing the following tasks:

    Create an index that maps IDs to names
    Create and execute an enrich policy
    Create an ingest pipeline that uses the enrich policy
    Add an object to the index mapping
    Update the documents using the ingest pipeline



## a) Terms Aggregation

Run the terms aggregation on the category field of the blogs_fixed2 index.

REQUEST

```
GET blogs_fixed2/_search
{
  "size": 0,
  "aggs": {
    "NAME": {
      "terms": {
        "field": "category",
        "size": 10
      }
    }
  }
}
```

RESPONSE

```
{
  "took": 8,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3500,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "NAME": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "bltfaae4466058cc7d6",
          "doc_count": 660
        },
        {⇔},
        {⇔},
        {⇔},
        {⇔},
        {⇔},
        {⇔}
      ]
    }
  }
}
```


# Review

- Denormalizing your data enables you to quickly and easily search across multiple fields in a single query without joining datasets.
- How do you create an enrich index? Create an enrich policy then execute it. The enriched index is created from a policy. The enriched index can then be used in an ingest pipeline in the enrich processor to add detailed data to incoming documents.
- Once created, you can’t update or change an enrich policy. Create and execute a new enrich policy.
